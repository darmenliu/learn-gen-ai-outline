# 面向软件工程师的生成式AI学习大纲

随着AI大模型的出现，生成式AI已经成为了科技界的新宠，无论是AI绘画、AI写作、AI编程、AI音乐、AI视频，还是AI对话，都离不开生成式AI。中国甚至提出了“AI+”战略，将AI与各行各业相结合，以实现产业升级和转型。就在最近中国教育部办公厅通知，将加强中小学人工智能教育，将AI教育纳入中小学课程体系，并鼓励学生学习AI相关知识。

在AI如此火热的背景下，软件工程师们其实处在学习和使用AI的前线，可以预见的是，未来所有的传统软件将被基于AI的软件所取代，软件工程师们将面临前所未有的挑战和机遇。因此，软件工程师们需要学习AI相关知识，以适应未来的发展。

最近每当和身边的同事聊起AI时，他们都会问我，作为一个软件工程师，应该如何学习AI？应该学习哪些知识？方向在哪里？

是啊，这其实也是我自己一直在思考的问题。

很庆幸，我本科学习数学和应用数学，研究生的时候很庆幸阴差阳错学习了人工智能方向。其实相比其他人，我有更好的数学基础，这成为我后来学习AI的一大优势。可惜15年前遇到经济危机，当时AI还处于早期阶段，考虑到现实情况，选择了软件开发。

不过由于一直对AI非常感兴趣，所以这些年一直都在关注AI的发展，也一直在学习AI相关的知识。通过这些年的积累，作为软件工程师我积累了很多软件开发和架构的经验，同时我也具有良好的AI基础和背景。我觉得这是我职业生涯的有一个转折点。AI的浪潮给了我新的机遇。

所以，我决定站在软件工程师的视角，将我这些年学习AI的经验和知识整理成一个学习大纲，分享给所有对AI感兴趣的软件工程师们。

大纲将主要分为四个部分：

- 基础知识：AI与生成式AI概述、机器学习基础及理论、神经网络基础
- 大语言模型(LLM)：什么是大语言模型、Transformer架构、预训练与微调、注意力机制、大语言模型的训练
- 生成式AI应用：Prompt Engineering、RAG (Retrieval-Augmented Generation)、AI Agent、文本生成应用、多模态生成
- 工程实践：常用的提示词模板、平台及工具、大语言模型类型、图像生成模型、音乐生成模型。

大家可以持续关注我的博客，我会持续更新这部分内容。并且收集相关的学习资料，分享给大家。

## 第一部分：基础知识

基础知识部分主要介绍AI与生成式AI的基本概念、机器学习基础及理论、神经网络基础等，这部分内容涉及基础算法、理论及架构等，需要有良好的数学基础。不过这部分如果能够坚持啃下来的话，一定会对AI有更深刻的理解。不过大部分人可以主要关注机器学习基础及理论、神经网络基本原理部分，因为这部分内容是生成式AI的基础，帮助你能够更好的理解大语言模型。

### AI与生成式AI概述
- 人工智能基本概念
- AI及生成式AI
- 专家系统
- 搜索算法

### 机器学习基础及理论
- 机器学习基础理论
- 模式识别和模式分类
    - 模式分类的基本原理
        - 决策理论
        - 分类器的作用
        - 模式识别的基本过程
    - 特征提取和选择
        - 特征提取
            - 特征空间的构建
            - 特征的表示与编码
            - 特征提取技术
                - 主成分分析
        - 特征选择
            - 特征重要性的评估方法
            - 特征选择算法
    - 分类方法
        - 统计分类
            - 贝叶斯分类器
            - Fisher线性判别分析（LDA）
            - 支持向量机（SVM）
        - 距离度量与非参数方法
            - 最近邻分类器（k-NN）
            - 距离度量（欧氏距离、曼哈顿距离、余弦相似度等）
    - 聚类与无监督学习
        - 聚类
            - k-Means聚类
            - 层次聚类
            - DBSCAN聚类
        - 无监督学习
            - 主成分分析（PCA
            - 自编码器（AutoEncoder）
            - 独立成分分析（ICA）
            - 隐变量模型
            - 非负矩阵分解（NMF）
    - 评估与优化
        - 评估指标
            - 准确率、召回率、F1值
            - ROC曲线、AUC值
        - 交叉验证
        - 超参数调优
            - 网格搜索
            - 随机搜索
            - 贝叶斯优化
            - 模型正则化技术（L1/L2正则化）
    - 贝叶斯方法与概率模型
        - 贝叶斯方法
            - 贝叶斯定理
            - 贝叶斯网络
        - 概率模型
            - 隐马尔可夫模型（HMM）
            - 高斯混合模型（GMM）
    - 异常检测与异常分类
    - 多模态模式识别
    - 图像识别
- 机器学习基础算法
    - 决策树
    - 贝叶斯网络
    - 回归分析
    - 支持向量机
    - K近邻算法
    - 遗传算法
    - 集成学习
        - Bagging方法（如随机森林）
        - Boosting方法（如AdaBoost、XGBoost）

### 神经网络基础
- 神经网络基本原理
    - 模拟生物神经系统的计算模型
    - 神经元模型
        - 神经元
        - 权重
        - 偏置
        - 激活函数
        - 损失函数
    - 神经网络的层次结构
        - 输入层
        - 隐藏层
        - 输出层
    - 常见激活函数
        - Sigmoid
        - Tanh
        - ReLU（Rectified Linear Unit）
        - Leaky ReLU
        - Softmax
    - 损失函数
        - 均方误差（MSE）
        - 交叉熵损失函数
- 神经网络训练
    - 前向传播
    - 反向传播
    - 优化算法
        - 梯度下降
        - 随机梯度下降
        - Adam
        - RMSprop
        - Adagrad
        - Momentum
- 正则化
    - L1正则化
    - L2正则化
    - Dropout
    - Batch Normalization

- 深度学习
    - 前馈神经网络（Feedforward Neural Network, FNN）
    - 卷积神经网络（Convolutional Neural Network, CNN）
    - 循环神经网络（Recurrent Neural Network, RNN）
    - 自编码器（Autoencoder）
    - 生成对抗网络（Generative Adversarial Network, GAN）
    - 图神经网络（Graph Neural Network, GNN）
    - 注意力模型（Attention Mechanism
    - 深度强化学习模型


## 第二部分：大语言模型(LLM)

这部分的内容主要介绍大语言模型的基本概念、架构、预训练与微调、注意力机制等，这部分内容是生成式AI的核心理论，可以指导你如何设计和构建大语言模型。同时也可以教你如何训练大语言模型，以及如何部署大语言模型。

结合软件工程师在软件开发和部署方面的经验，推荐软件工程师可以重点关注搭语言模型的微调，部署，API服务等方面的技术。同时我个人觉得LLM OPs是一个很好的方向，可以结合软件工程师的开发经验，开发相应的工具和平台，加速大语言模型的创新，开发和部署。

### 什么是大语言模型
- 基于深度学习的自然语言处理模型
- 能够生成、理解和操作自然语言
- 典型模型：GPT（OpenAI）、BERT（Google）、LLaMA（Meta）

### Transformer架构
- 基础构件：多头注意力机制、前馈网络、位置编码
- 关键优点：并行处理长序列数据
- 变体：BERT、GPT、T5等

### 预训练与微调
- 预训练：在大规模语料库上训练语言模型
- 微调：针对特定任务的优化
- 自监督学习：掩码语言模型（MLM）、因果语言模型（CLM）

### 注意力机制
- 点积注意力（Scaled Dot-Product Attention）
- 自注意力与全局依赖建模
- 多头注意力的效果与优化

### 大语言模型的训练
#### 训练数据
- 数据来源：文本语料库、网页爬取内容、对话记录
- 数据清洗与标注
- 数据增强技术

#### 训练策略
- 监督学习：使用标注数据训练
- 半监督学习：结合标注和非标注数据
- 强化学习：如使用奖励模型优化（RLHF, 人类反馈强化学习）

#### 模型训练资源
- 大规模分布式计算
- GPU/TPU硬件加速
- 并行与分布式训练技术（如数据并行、模型并行）

#### 大模型的部署和维护
    - 本地部署
    - 云端分布式部署
    - API 及服务

## 第三部分：生成式AI应用

生成式AI应用部分主要涉及开发基于大语言模型应用的基础理论和技术，通过这些技术，使得你有能力开发和构建基于大语言模型的应用。我推荐软件工程师们可以重点关注这部分内容涉及的技术和理论以及相关的工具。相比transformer及深度学习相关的基础理论和算法，这部分内容更偏向于应用和实践。由于软件工程师们有良好的软件开发基础，所以这部分内容更容易上手。

### Prompt Engineering
- 什么是提示词工程
- 提示词的基本结构
- 提示词工程技术分类
    - zero shot
    - few shot
    - chain of thought
    - React prompt
    - tree of thought
    - prompt chain
    - Reflexion
    - Self-Consistency

### RAG (Retrieval-Augmented Generation)
- RAG模型架构
    - 检索
    - 生成
- 向量数据库
- 知识库
- RAG应用
    - 问答系统
    - 智能客服
    - 文本生成
    - 代码生成
    - 多模态生成
- RAG 编程框架
    - langchain
    - llamaindex
### AI Agent
- Agent架构模式
    - Agent 基本架构
    - 工具
    - 任务规划
    - 多Agent协作
    - 记忆与知识库
    - Agent评估方法
- 多Agent体
- Agent 编程框架
    - langchain
    - autogen
    - openAI

### 文本生成应用
- 对话系统
- 文本摘要
- 代码生成
    - Code Pilot
    - Code Agent
- 创意写作
- 多语言翻译

### 多模态生成
- 文本到图像生成
- 图像到文本描述
- 视频生成
- 音频生成
- 跨模态转换
- OCR与语音识别

## 第四部分：工程实践

### 常用的提示词模板

### 平台及工具

#### 智能体低代码

- COZE
- DIFY

#### AI 编程助手

- Github Copilot
- Cursor
- Codeium
    - Windsurf

#### 图像及视频生成
- Madejourney
- Stable Diffusion
- Civitai
- Flux

#### 音乐生成

- suno
- udio

### 大语言模型

- OpenAI models
    - GPT4
    - GPT4o
- Claude models
    - claude 3.5
- Google models
    - Gemini 1.5
- Aliyun
    - qianwen 2.5
- Deepseek
    - deepseek 2.5
- Llama models
    - llama 3.1
    - llama 3.2
- Mixtral
    - mixtral 

### 图像生成模型

- DALL-E
- Stable diffusion models
- Flux models

### 音乐生成模型

[AI 工具集](https://ai-bot.cn/)
[参考链接: Generative AI Handbook](https://genai-handbook.github.io)

